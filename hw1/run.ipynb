{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import importlib\n",
    "import pickle\n",
    "\n",
    "import data_utils\n",
    "import model_utils\n",
    "import train_utils\n",
    "import evaluation\n",
    "import submission\n",
    "importlib.reload(data_utils)\n",
    "importlib.reload(model_utils)\n",
    "importlib.reload(train_utils)\n",
    "importlib.reload(evaluation)\n",
    "importlib.reload(submission)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.data import TabularDataset, Field, RawField, BucketIterator, Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = data_utils.prep_all_data(\n",
    "    train_file=\"train.csv\", val_file=\"holdout_test.csv\", test_file=\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, LR: 0.01, Train Loss: 208.0490, Val Loss: 54.5679, Val f1 0.895\n",
      "Epoch: 1, LR: 0.01, Train Loss: 48.5305, Val Loss: 21.6976, Val f1 0.957\n",
      "Epoch: 2, LR: 0.01, Train Loss: 20.6048, Val Loss: 8.8090, Val f1 0.989\n",
      "Epoch: 3, LR: 0.01, Train Loss: 11.6165, Val Loss: 5.6757, Val f1 0.989\n",
      "Epoch: 4, LR: 0.01, Train Loss: 6.7758, Val Loss: 2.3491, Val f1 0.998\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(model_utils)\n",
    "m = model_utils.BaseModelNGram()\n",
    "result = train_utils.train(train_data, val_data, m, device=DEVICE,\n",
    "                          lr=1e-2, print_freq=1, max_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(result[\"trained_model\"], \"./data/model_checkpoints/ngram_MLP_Jan31_all_train.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, LR: 0.01, Train Loss: 298.4011, Val Loss: 152.3056, Val f1 0.623\n",
      "Epoch: 1, LR: 0.01, Train Loss: 119.8285, Val Loss: 83.6388, Val f1 0.824\n",
      "Epoch: 2, LR: 0.01, Train Loss: 66.6539, Val Loss: 43.1478, Val f1 0.932\n",
      "Epoch: 3, LR: 0.01, Train Loss: 37.1929, Val Loss: 28.2445, Val f1 0.973\n",
      "Epoch: 4, LR: 0.01, Train Loss: 21.9316, Val Loss: 17.2099, Val f1 0.984\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(model_utils)\n",
    "m = model_utils.GRU()\n",
    "result = train_utils.train(train_data, val_data, m, device=DEVICE,\n",
    "                          lr=1e-2, print_freq=1, max_epoch=5)\n",
    "torch.save(result[\"trained_model\"], \"./data/model_checkpoints/GRU_Jan31_all_train.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_phrase, val_data_phrase, test_data_phrase = data_utils.prep_all_data(\n",
    "    path=\"./data/movie_name_condensed_data/\", \n",
    "    train_file=\"train.csv\", val_file=\"holdout_test.csv\", test_file=\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, LR: 0.01, Train Loss: 204.9415, Val Loss: 57.7080, Val f1 0.877\n"
     ]
    }
   ],
   "source": [
    "m = model_utils.BaseModelNGram(path=\"./data/movie_name_condensed_data/\")\n",
    "result = train_utils.train(train_data_phrase, val_data_phrase, m, device=DEVICE,\n",
    "                          lr=1e-2, print_freq=5, max_epoch=5)\n",
    "torch.save(result[\"trained_model\"], \"./data/model_checkpoints/ngram_phrase_MLP_Jan31_all_train.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, LR: 0.01, Train Loss: 17.0882, Val Loss: 5.9968, Val f1 0.989\n",
      "Epoch: 1, LR: 0.01, Train Loss: 10.8891, Val Loss: 3.2211, Val f1 0.992\n",
      "Epoch: 2, LR: 0.01, Train Loss: 7.0593, Val Loss: 2.8849, Val f1 0.993\n",
      "Epoch: 3, LR: 0.01, Train Loss: 4.6497, Val Loss: 1.5977, Val f1 0.998\n",
      "Epoch: 4, LR: 0.01, Train Loss: 4.4143, Val Loss: 2.3155, Val f1 0.995\n"
     ]
    }
   ],
   "source": [
    "dm = model_utils.GRU(path=\"./data/movie_name_condensed_data/\")\n",
    "result = train_utils.train(train_data_phrase, val_data_phrase, m, device=DEVICE,\n",
    "                          lr=1e-2, print_freq=1, max_epoch=5)\n",
    "torch.save(result[\"trained_model\"], \"./data/model_checkpoints/GRU_phrase_Jan31_all_train.mdl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'evaluation' from '/home/molly/Desktop/CSE244_ML_for_NLP/hw1/evaluation.py'>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(submission)\n",
    "importlib.reload(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_gram = torch.load(\"./data/model_checkpoints/ngram_MLP_Jan31_all_train.mdl\")\n",
    "m_gram_phrase = torch.load(\"./data/model_checkpoints/ngram_phrase_MLP_Jan31_all_train.mdl\")\n",
    "m_GRU = torch.load(\"./data/model_checkpoints/GRU_Jan31_all_train.mdl\")\n",
    "m_GRU_phrase = torch.load(\"./data/model_checkpoints/GRU_phrase_Jan31_all_train.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = submission.Ensemble(models=[m_gram, m_gram_phrase, m_GRU_phrase, m_GRU], \n",
    "                               val_data=[val_data, val_data_phrase, val_data_phrase, val_data],\n",
    "                               test_data=[test_data, test_data_phrase, test_data_phrase, test_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate submission file for kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = ensemble.get_ensemble_result(submission=True)\n",
    "ensemble.save_submission_file(\"all_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
