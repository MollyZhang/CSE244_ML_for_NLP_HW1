{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import importlib\n",
    "import pickle\n",
    "\n",
    "import data_utils\n",
    "import model_utils\n",
    "import train_utils\n",
    "import evaluation\n",
    "import submission\n",
    "importlib.reload(data_utils)\n",
    "importlib.reload(model_utils)\n",
    "importlib.reload(train_utils)\n",
    "importlib.reload(evaluation)\n",
    "importlib.reload(submission)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.data import TabularDataset, Field, RawField, BucketIterator, Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"\n",
    "HOLDOUT = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read data and put in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = data_utils.prep_all_data(\n",
    "    device=DEVICE, use_holdout_test=False, ngram=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, LR: 0.01, Train Loss: 239.5189, Val Loss: 97.5010, Val f1 0.743\n",
      "Epoch: 5, LR: 0.01, Train Loss: 5.0058, Val Loss: 67.7320, Val f1 0.834\n",
      "Epoch: 10, LR: 0.01, Train Loss: 3.0623, Val Loss: 83.7059, Val f1 0.819\n",
      "Epoch: 15, LR: 0.001, Train Loss: 2.6288, Val Loss: 95.3713, Val f1 0.821\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(model_utils)\n",
    "vocab = np.load(\"./data/1grams.npy\")\n",
    "m = model_utils.BaseModelNGram()\n",
    "result = train_utils.train(train_data, val_data, m, device=DEVICE,\n",
    "                          lr=1e-2, print_freq=5, max_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(result[\"trained_model\"], \"./data/model_checkpoints/ngram_MLP_Jan30.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, LR: 0.01, Train Loss: 321.0513, Val Loss: 260.8454, Val f1 0.518\n",
      "Epoch: 5, LR: 0.01, Train Loss: 12.2597, Val Loss: 122.1696, Val f1 0.785\n",
      "Epoch: 10, LR: 0.01, Train Loss: 1.9306, Val Loss: 121.0964, Val f1 0.782\n",
      "Epoch: 15, LR: 0.01, Train Loss: 0.7654, Val Loss: 111.8629, Val f1 0.789\n",
      "Epoch: 20, LR: 0.01, Train Loss: 0.4493, Val Loss: 111.4513, Val f1 0.796\n",
      "Epoch: 25, LR: 0.01, Train Loss: 0.3529, Val Loss: 110.3826, Val f1 0.797\n",
      "Epoch: 30, LR: 0.01, Train Loss: 0.2530, Val Loss: 115.8223, Val f1 0.796\n",
      "Epoch: 35, LR: 0.01, Train Loss: 0.5006, Val Loss: 117.0286, Val f1 0.794\n",
      "Epoch: 40, LR: 0.001, Train Loss: 0.4303, Val Loss: 117.0088, Val f1 0.800\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(model_utils)\n",
    "m = model_utils.GRU()\n",
    "result = train_utils.train(train_data, val_data, m, device=DEVICE,\n",
    "                          lr=1e-2, print_freq=5, max_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(result[\"trained_model\"], \"./data/model_checkpoints/GRU_Jan30.mdl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble f1 val score: 0.8939802336028755\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data, test_data = data_utils.prep_all_data(\n",
    "    device=DEVICE, use_holdout_test=False, ngram=1)\n",
    "m_gram = torch.load(\"./data/model_checkpoints/ngram_MLP_Jan30.mdl\")\n",
    "m_emb = torch.load(\"./data/model_checkpoints/GRU_Jan30.mdl\")\n",
    "ensemble = submission.Ensemble(model1=m_gram, model2=m_emb, \n",
    "                               val_data=val_data, test_data=test_data)\n",
    "df = ensemble.get_ensemble_result(submission=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate submission file for kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ensemble.get_ensemble_result(submission=True)\n",
    "ensemble.save_submission_file(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1084, 3)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
